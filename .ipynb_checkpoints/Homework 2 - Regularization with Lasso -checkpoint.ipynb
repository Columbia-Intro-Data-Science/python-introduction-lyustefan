{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "In this homework, you'll be required to load in a dataset which has about 500 features. By using\n",
    "Lasso ($L^1$) regression, we'll find the optimal constraint on the $L^1$ norm which gives us the best\n",
    "$R^2$. Then we'll plot the results.\n",
    "\n",
    "Recall we minimize the following on ** training data: $(x_i,y_i)$**\n",
    "\n",
    "$$\\min_{\\beta} \\frac{1}{N} \\sum_{i=1}^N (y_i - \\beta \\cdot x_i)^2 + \\lambda \\|\\beta \\|_{L^1}.$$\n",
    "\n",
    "\n",
    "Denoting $\\beta_{\\lambda}$ as the minimum of the above, we then choose $\\lambda$ to maximize $R^2$ on **testing data: $(x_j,y_j)$**\n",
    "\n",
    "$$ \\max_{\\lambda} 1 - \\frac{\\sum_{j} (y_j - \\beta_{\\lambda} \\cdot x_j)^2}{\\sum_j (y_j - \\bar y)^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load in hw2data.csv from ../data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.382732</td>\n",
       "      <td>-0.034242</td>\n",
       "      <td>1.096347</td>\n",
       "      <td>-0.234216</td>\n",
       "      <td>-0.347451</td>\n",
       "      <td>-0.581268</td>\n",
       "      <td>-1.632635</td>\n",
       "      <td>-1.567768</td>\n",
       "      <td>-1.179158</td>\n",
       "      <td>1.301428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178793</td>\n",
       "      <td>-0.799422</td>\n",
       "      <td>0.240788</td>\n",
       "      <td>0.289121</td>\n",
       "      <td>0.412871</td>\n",
       "      <td>-0.198399</td>\n",
       "      <td>0.094192</td>\n",
       "      <td>-1.147611</td>\n",
       "      <td>-0.358114</td>\n",
       "      <td>-2.663126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555963</td>\n",
       "      <td>0.892474</td>\n",
       "      <td>-0.422315</td>\n",
       "      <td>0.104714</td>\n",
       "      <td>0.228053</td>\n",
       "      <td>0.201480</td>\n",
       "      <td>0.540774</td>\n",
       "      <td>-1.818078</td>\n",
       "      <td>-0.049324</td>\n",
       "      <td>0.239034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740137</td>\n",
       "      <td>-0.565498</td>\n",
       "      <td>0.476031</td>\n",
       "      <td>-2.158069</td>\n",
       "      <td>1.318551</td>\n",
       "      <td>-0.239297</td>\n",
       "      <td>-0.246794</td>\n",
       "      <td>-1.079343</td>\n",
       "      <td>-0.114226</td>\n",
       "      <td>10.399650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013240</td>\n",
       "      <td>-0.121945</td>\n",
       "      <td>0.339059</td>\n",
       "      <td>-0.589632</td>\n",
       "      <td>-0.895816</td>\n",
       "      <td>0.548328</td>\n",
       "      <td>0.098667</td>\n",
       "      <td>0.197181</td>\n",
       "      <td>1.059027</td>\n",
       "      <td>-1.022564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.739936</td>\n",
       "      <td>1.315138</td>\n",
       "      <td>-0.323457</td>\n",
       "      <td>0.197828</td>\n",
       "      <td>0.097751</td>\n",
       "      <td>1.401523</td>\n",
       "      <td>0.158434</td>\n",
       "      <td>-1.141901</td>\n",
       "      <td>-1.310970</td>\n",
       "      <td>-21.762801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.532921</td>\n",
       "      <td>-1.711970</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>-0.958374</td>\n",
       "      <td>-0.080812</td>\n",
       "      <td>-0.703859</td>\n",
       "      <td>-0.770784</td>\n",
       "      <td>-0.480845</td>\n",
       "      <td>0.703586</td>\n",
       "      <td>0.929145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473488</td>\n",
       "      <td>1.855246</td>\n",
       "      <td>1.415656</td>\n",
       "      <td>-0.302746</td>\n",
       "      <td>0.989679</td>\n",
       "      <td>0.585851</td>\n",
       "      <td>1.136388</td>\n",
       "      <td>0.671617</td>\n",
       "      <td>-0.974167</td>\n",
       "      <td>2.139453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.619685</td>\n",
       "      <td>0.572627</td>\n",
       "      <td>1.902618</td>\n",
       "      <td>-0.775664</td>\n",
       "      <td>-0.188090</td>\n",
       "      <td>-1.035748</td>\n",
       "      <td>1.177830</td>\n",
       "      <td>-2.305167</td>\n",
       "      <td>-2.263660</td>\n",
       "      <td>0.375020</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.303220</td>\n",
       "      <td>0.466751</td>\n",
       "      <td>0.161106</td>\n",
       "      <td>0.320032</td>\n",
       "      <td>2.079177</td>\n",
       "      <td>-0.907466</td>\n",
       "      <td>-0.192404</td>\n",
       "      <td>-1.212516</td>\n",
       "      <td>-0.080599</td>\n",
       "      <td>0.194017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.382732 -0.034242  1.096347 -0.234216 -0.347451 -0.581268 -1.632635   \n",
       "1  0.555963  0.892474 -0.422315  0.104714  0.228053  0.201480  0.540774   \n",
       "2  0.013240 -0.121945  0.339059 -0.589632 -0.895816  0.548328  0.098667   \n",
       "3 -1.532921 -1.711970  0.046135 -0.958374 -0.080812 -0.703859 -0.770784   \n",
       "4 -1.619685  0.572627  1.902618 -0.775664 -0.188090 -1.035748  1.177830   \n",
       "\n",
       "          7         8         9    ...           491       492       493  \\\n",
       "0 -1.567768 -1.179158  1.301428    ...      0.178793 -0.799422  0.240788   \n",
       "1 -1.818078 -0.049324  0.239034    ...     -0.740137 -0.565498  0.476031   \n",
       "2  0.197181  1.059027 -1.022564    ...     -0.739936  1.315138 -0.323457   \n",
       "3 -0.480845  0.703586  0.929145    ...      0.473488  1.855246  1.415656   \n",
       "4 -2.305167 -2.263660  0.375020    ...     -1.303220  0.466751  0.161106   \n",
       "\n",
       "        494       495       496       497       498       499          y  \n",
       "0  0.289121  0.412871 -0.198399  0.094192 -1.147611 -0.358114  -2.663126  \n",
       "1 -2.158069  1.318551 -0.239297 -0.246794 -1.079343 -0.114226  10.399650  \n",
       "2  0.197828  0.097751  1.401523  0.158434 -1.141901 -1.310970 -21.762801  \n",
       "3 -0.302746  0.989679  0.585851  1.136388  0.671617 -0.974167   2.139453  \n",
       "4  0.320032  2.079177 -0.907466 -0.192404 -1.212516 -0.080599   0.194017  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"hw2data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Set y to be the y variable in the dataframe from a and X to be the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -2.663126\n",
       "1      10.399650\n",
       "2     -21.762801\n",
       "3       2.139453\n",
       "4       0.194017\n",
       "5       9.640786\n",
       "6       4.490042\n",
       "7      -0.657482\n",
       "8       0.073541\n",
       "9     -13.133014\n",
       "10     14.794960\n",
       "11      1.028366\n",
       "12    -14.122513\n",
       "13    -16.941651\n",
       "14      5.727403\n",
       "15     12.835040\n",
       "16      3.009829\n",
       "17     -8.747204\n",
       "18     -4.617145\n",
       "19    -12.926535\n",
       "20     -4.922311\n",
       "21     12.249172\n",
       "22     -2.012608\n",
       "23     -6.975120\n",
       "24     -4.717115\n",
       "25      7.976029\n",
       "26     10.533411\n",
       "27     15.248268\n",
       "28     -4.613508\n",
       "29      8.095869\n",
       "         ...    \n",
       "195     9.353331\n",
       "196    -0.659832\n",
       "197    -3.162216\n",
       "198     7.600125\n",
       "199    -1.249834\n",
       "200   -13.405165\n",
       "201     5.124562\n",
       "202    -1.345065\n",
       "203     4.429183\n",
       "204     4.202132\n",
       "205     1.579348\n",
       "206    -1.006836\n",
       "207    -4.946343\n",
       "208    -5.003751\n",
       "209     6.442390\n",
       "210     6.499555\n",
       "211     9.717460\n",
       "212     4.402044\n",
       "213   -15.349713\n",
       "214     0.634336\n",
       "215     2.670747\n",
       "216    -4.205346\n",
       "217   -11.067010\n",
       "218    -2.945159\n",
       "219    -0.696138\n",
       "220    -8.112017\n",
       "221     0.209439\n",
       "222     9.039615\n",
       "223    -5.977865\n",
       "224    -8.548734\n",
       "Name: y, Length: 225, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,500]\n",
    "X = df.iloc[:,:df.shape[1]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) As shown in the Booking.com example, using Lasso regression, find the regularization strength\n",
    "which optimizes the $R^2$. \n",
    "\n",
    "**Hint:** Take a range of alpha from `np.logspace(-8,-3,1000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Plot the training perforamnce versus the testing performance, and observe whree the test performance is\n",
    "maximized. I've written an outline of the code you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# Fill these in\n",
    "alphas = []\n",
    "train_errors=[]\n",
    "test_errors=[]\n",
    "alpha_optim=0\n",
    "\n",
    "\n",
    "\n",
    "plt.semilogx(alphas, train_errors, label='Train')\n",
    "plt.semilogx(alphas, test_errors, label='Test')\n",
    "plt.vlines(alpha_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "           linewidth=3, label='Optimum on test')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Performance')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Plot the top coefficients based on this optimal paramter. Why do you think so many are zero? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Compute the $R^2$ with the optimal coefficient found above on 5 folds using cross_val_score and plot the\n",
    "results. Does the model work well on all random subsets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Repeat e) but using cross validation. Use error bars on the features which are the standard deviation of the \n",
    "coefficiens obtained above. For this problem I\"ll walk you through the code. You just need to apply your optimal\n",
    "$\\alpha$ found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import preprocessing\n",
    "def run_cv_coeffs(X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    coeffs=[]\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        coeffs.append(clf.coef_)\n",
    "    return coeffs\n",
    "\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled = X.as_matrix().astype(np.float)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "coeffs=run_cv_coeffs(X_scaled,np.array(y),Lasso,alpha=alpha_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coeffs(coeffs):\n",
    "    coeffs_avgd = [(coeffs[0][i] + coeffs[1][i] + coeffs[2][i] + coeffs[3][i] + coeffs[4][i])/5 for i in range(0,len(X.columns))]\n",
    "    coeffs_std = [np.std([coeffs[0][i],coeffs[1][i],coeffs[2][i],coeffs[3][i],coeffs[4][i]]) for i in range(0,len(X.columns))]\n",
    "    return coeffs_avgd, coeffs_std\n",
    "coeffs_avg,coeffs_std=get_coeffs(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16ef6d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCoeffs = pd.DataFrame({'type':X.columns.values, 'coef':coeffs_avg, 'std':coeffs_std})\n",
    "dfCoeffs = dfCoeffs[(dfCoeffs['coef']>1) |(dfCoeffs['coef']<-1) ]\n",
    "plt.figure(figsize=(15,15))\n",
    "dfCoeffs_sorted = dfCoeffs.sort(['coef'])[::-1]\n",
    "yerr_vals = dfCoeffs_sorted['std'].values\n",
    "dfCoeffs_sorted.plot(x='type',y='coef',kind='bar',yerr=yerr_vals,figsize=(15,15))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
